{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtQ+W7+5Gvy4yvnA+jDMgd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovedeepkaursaini/CustomerAnalysisGPT/blob/main/Client_feedback_and_survey_analysis_with_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Libraries"
      ],
      "metadata": {
        "id": "pzvYVmCWj6OS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrGGdtt42Tqz",
        "outputId": "f43099a2-7faa-4632-b881-ed1f7e7d15da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n"
          ]
        }
      ],
      "source": [
        "#install libraries\n",
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Upload Dataset"
      ],
      "metadata": {
        "id": "u-t-3_Ytj_LN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the Excel file to the notebook environment.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "9SY2ZRH82mhv",
        "outputId": "97075bf4-bdcd-4f50-a788-2cb4f077afef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12974ea8-6970-4e43-a811-cab05252ec2d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12974ea8-6970-4e43-a811-cab05252ec2d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving client_feedback_survey.xlsx to client_feedback_survey (3).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Dataframe"
      ],
      "metadata": {
        "id": "_fCBmzenk-FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "# Access the uploaded file\n",
        "excel_file_path = next(iter(uploaded))\n",
        "\n",
        "# read the data from the Excel file.\n",
        "# use pandas to read the data into a DataFrame:\n",
        "import pandas as pd\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Convert the DataFrame to a list of dictionaries for easier processing\n",
        "records = df.to_dict(orient='records')"
      ],
      "metadata": {
        "id": "_dKH9yLxKPpT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Functions for Prompt Engineering"
      ],
      "metadata": {
        "id": "ekaKvIaLlC0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a prompt based on the Excel data\n",
        "def generate_prompt_from_record(user_question):\n",
        "    prompt_template = \"\"\"\n",
        "    Chat with given data table containing client feedback and survey data. The table has the following keys or columns:\n",
        "    - 'Client Name': The name of the client.\n",
        "    - 'Address': The client's address.\n",
        "    - 'Service Period': The period during which services were provided.\n",
        "    - 'Service Type': The type of service provided, such as Property & Casualty, Employee Benefits, Risk Management, or Captive Insurance.\n",
        "    - 'Overall Satisfaction': A rating from 1 to 10 indicating overall satisfaction.\n",
        "    - 'Service Quality': A qualitative assessment of service quality (Very Poor, Poor, Average, Good, Excellent).\n",
        "    - 'Understanding Needs': How well the service provider understood the client's needs.\n",
        "    - 'Communication': A rating from 1 to 10 on communication effectiveness.\n",
        "    - 'Customization and Flexibility': A qualitative assessment of the service's customization and flexibility.\n",
        "    - 'Expertise and Advice': Confidence in the provided expertise and advice.\n",
        "    - 'Claim Support': Satisfaction with claim support, if applicable.\n",
        "    - 'Pricing and Value': The perceived value of the services in relation to their cost.\n",
        "    - 'Referral Likelihood': A rating from 1 to 10 on the likelihood of referring others to the service.\n",
        "    - 'Improvement and Feedback': General feedback for service improvement.\n",
        "    - 'General Comment': Additional comments provided by the client.\n",
        "\n",
        "    Do not respond to any user question that is not related to provided feedback and survey dataset.\n",
        "\n",
        "    Below is a specific client feedback record; use it as your context to answer the question at the end. If you don't know the answer, just respond as 'Not Found', don't try to make up an answer:\n",
        "      {client_feedback}\n",
        "    Question:\n",
        "      {user_question}\n",
        "    Answer:\n",
        "    \"\"\".format(client_feedback=records, user_question=user_question)\n",
        "    return prompt_template"
      ],
      "metadata": {
        "id": "hBxPompUKUlV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Function for GPT Call"
      ],
      "metadata": {
        "id": "69jxWAL0lOuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function for calling openai GPT\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
        "def gpt_client(user_question):\n",
        "  client = OpenAI()\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-4-1106-preview\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant who is expert in analyzing provided data. Do not respond to any user question that is not related to provided feedback and survey dataset.\"},\n",
        "        {\"role\": \"user\", \"content\": generate_prompt_from_record(user_question)}],\n",
        "    temperature=0,\n",
        "    seed=21\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "HU65gHUKN0Rd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#User Playground - ask questions"
      ],
      "metadata": {
        "id": "BEzzPPowlToV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt_client(\"List of clients with have 'overall satisfaction' ratings of greater than 10. Response should be in following format: 'Client name : overall satisfaction rating'\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLqYY01R4xlS",
        "outputId": "cf42beab-83f3-4fe8-da82-c47c086e7bf9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not Found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt_client(\"List of top 5 clients with have 'overall satisfaction' ratings equal to 10. Response should be in following format: 'Client name : overall satisfaction rating'\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOtWxk46QLd8",
        "outputId": "831c3535-da93-43ac-c3cb-f33a350628a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. John C : 10\n",
            "2. Robert J : 10\n",
            "3. Emily B : 10\n",
            "4. Robert L : 10\n",
            "5. Anna E2 : 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt_client(\"Summarize the 'feedback and improvement' section and list top 5 actionable items?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAq34n2TWcuC",
        "outputId": "b9081697-cf1a-41e0-950a-7e5d439b48ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the 'Improvement and Feedback' comments from the client feedback records, here are the top 5 actionable items:\n",
            "\n",
            "1. **Enhance Communication and Information Sharing**: Clients have expressed a need for better communication strategies, including more proactive updates and keeping clients better informed. This could involve improving the mobile app functionality for on-the-go access, enhancing the user interface of online platforms, and providing more comprehensive training and resources.\n",
            "\n",
            "2. **Improve Pricing Transparency and Value**: Several clients have mentioned the need for more transparent pricing models and options. Offering more competitive pricing and ensuring that clients perceive a good value for the services provided are crucial steps.\n",
            "\n",
            "3. **Streamline Onboarding and Claims Processing**: Clients are looking for a more streamlined onboarding process for new clients and faster claims processing. This could involve simplifying procedures, reducing paperwork, and enhancing online portal efficiency.\n",
            "\n",
            "4. **Customization and Flexibility in Services**: Clients have indicated a desire for more customized insurance packages tailored to specific needs and more flexible payment options. Expanding the range of services to cover emerging risks and sectors is also suggested.\n",
            "\n",
            "5. **Enhance Client Engagement and Support**: Feedback indicates a need for more opportunities for client feedback and engagement, as well as strengthening customer service with additional support channels. Introducing loyalty programs or incentives for long-term clients could also be beneficial.\n",
            "\n",
            "These actionable items are derived from recurring themes in the feedback provided by clients and represent areas where the service provider can focus on making improvements to meet client expectations better.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt_client(\"identify areas for improvement based on the feedback\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzpjGK943QPt",
        "outputId": "74f4bcc3-7f1e-4174-9bdd-64b51acdb36b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the feedback provided in the dataset, the following areas for improvement have been identified:\n",
            "\n",
            "1. **Communication**: Several clients have mentioned the need for better communication. Improvements could include more proactive updates, enhanced communication strategies, and additional support channels.\n",
            "\n",
            "2. **Customization and Flexibility**: Clients have expressed a desire for more customized insurance packages and flexible service options. The company should consider offering more tailored solutions to meet individual client needs.\n",
            "\n",
            "3. **Pricing and Value**: There are concerns about the perceived value of the services in relation to their cost. The company should review its pricing models to ensure they are competitive and transparent.\n",
            "\n",
            "4. **Online Portal and Mobile App Functionality**: Clients have suggested that the online portal and mobile app could be more user-friendly and efficient. Enhancing the digital experience could lead to higher client satisfaction.\n",
            "\n",
            "5. **Onboarding Process**: Streamlining the onboarding process for new clients has been mentioned as an area for improvement, indicating that the current process may be too complicated or time-consuming.\n",
            "\n",
            "6. **Claim Support and Processing Time**: While some clients are satisfied with claim support, others have noted that claim processing could be faster. The company should look into reducing turnaround times for claims.\n",
            "\n",
            "7. **Expertise and Advice**: While some clients are confident in the expertise and advice provided, others are not. The company should ensure that all clients feel confident in the guidance they receive.\n",
            "\n",
            "8. **Educational Content and Resources**: Clients have requested more educational content to help them make informed decisions. Providing additional resources could enhance client knowledge and satisfaction.\n",
            "\n",
            "9. **Data Privacy and Security**: Improving data privacy and security measures has been mentioned, suggesting that clients are concerned about the protection of their information.\n",
            "\n",
            "10. **Sustainability and Ethical Practices**: Some feedback indicates a desire for the company to focus more on sustainability and ethical business practices.\n",
            "\n",
            "11. **Loyalty Programs and Incentives**: Introducing loyalty programs or incentives for long-term clients could improve client retention and satisfaction.\n",
            "\n",
            "12. **Employee Benefits Packages**: Clients are looking for more options and better customization in employee benefits packages.\n",
            "\n",
            "13. **Billing Issues**: A few clients have experienced billing issues, which indicates a need for better billing management and client communication regarding charges.\n",
            "\n",
            "By addressing these areas, the company can work towards enhancing client satisfaction and service quality.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt_client(\"tell me a story\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgS8qJgNmnFv",
        "outputId": "970fc127-6a65-4e04-f87c-1d7f0eb86196"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not Found\n"
          ]
        }
      ]
    }
  ]
}